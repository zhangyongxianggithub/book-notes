### 函数
在Table API与SQL中使用函数进行数据的转换。
1. 函数类型
- 系统函数，没有名称空间，直接通过名称引用;
- Catalog函数，属于Catalog与数据库，因此它们拥有Catalog和数据库命名空间，用户可以通过全/部分限定名（catalog.db.func 或 db.func）或者函数名 来对 Catalog 函数进行引用;
- 临时函数, 有用户创建，仅在会话的生命周期内有效;
- 持久化函数，存储在Catalog中，一致有效，在会话的整个生命周期内都有效；

根据上面的划分分为4种函数:
- 临时性系统函数;
- 系统函数;
- 临时性Catalog函数;
- Catalog函数

系统函数优先于Catalog函数，临时函数优先于持久化函数。Flink种可以通过精确/模糊2种方式引用函数:
- 精确函数引用，精确函数引用允许用户跨Catalog，跨数据库调用Catalog函数。 例如: `select mycatalog.mydb.myfunc(x) from mytable`和 `select mydb.myfunc(x) from mytable`;
- 模糊函数引用，用户只需要在SQL中指定函数名，比如:`select myfunc(x) from mytable`;

函数名相同，函数类型不同时，函数解析顺序才有意义，精确函数的解析顺序（因为系统函数没有命名空间，所以不会有系统函数）
- 临时性Catalog函数;
- Catalog函数;

模糊函数的解析顺序:
- 临时性系统函数;
- 系统函数;
- 临时性Catalog函数，在会话的当前Catalog和当前数据库中;
- Catalog函数，在会话的当前Catalog和当前数据库中;

### 系统(内置函数)
Table API/SQL提供了一组内置的数据转换函数，分为几种:
1. 标量函数

- **条件函数**

|SQL函数|Table函数|描述|
|:---|:---|:---|
|NULLIF(value1, value2)|不适用|如果value1==value2，返回null，否则返回value1|
1. 聚合函数
2. 时间间隔单位和时间点单位标识符
3. 列函数
### 自定义函数
自定义函数(UDF)是一种扩展开发机制，可以用来在查询语句里调用难以用其他方式表达的频繁使用的或者自定义的逻辑，自定义函数可以用JVM语言活着python实现，实现者可以在UDF中使用任意第三方库。
#### 概述
Flink有如下几种函数:
- 标量函数: 将标量值转换为新的标量值;
- 表值函数: 将标量值转换成新的行数据;
- 聚合函数: 将多行数据淋面的标量值转换成一个新标量值;
- 表值聚合函数: 将多行数据里面的标量值转换成新的行数据;
- 异步表值函数: 是异步查询外部数据系统的特殊函数.

标量与表值函数已经使用了新的基于数据类型的类型系统，聚合函数仍然使用基于TypeInformation的旧类型系统。一个例子如下:
```java
import org.apache.flink.table.api.*;
import org.apache.flink.table.functions.ScalarFunction;
import static org.apache.flink.table.api.Expressions.*;

// 定义函数逻辑
public static class SubstringFunction extends ScalarFunction {
  public String eval(String s, Integer begin, Integer end) {
    return s.substring(begin, end);
  }
}

TableEnvironment env = TableEnvironment.create(...);

// 在 Table API 里不经注册直接“内联”调用函数
env.from("MyTable").select(call(SubstringFunction.class, $("myField"), 5, 12));

// 注册函数
env.createTemporarySystemFunction("SubstringFunction", SubstringFunction.class);

// 在 Table API 里调用注册好的函数
env.from("MyTable").select(call("SubstringFunction", $("myField"), 5, 12));

// 在 SQL 里调用注册好的函数
env.sqlQuery("SELECT SubstringFunction(myField, 5, 12) FROM MyTable");
```
对于交互式会话，还可以在使用或者注册函数之前对其进行参数化，这样可以把函数实例而不是函数类用作临时函数，为确保函数实例可以用于集群环境，参数必须是可序列化的:
```java
import org.apache.flink.table.api.*;
import org.apache.flink.table.functions.ScalarFunction;
import static org.apache.flink.table.api.Expressions.*;

// 定义可参数化的函数逻辑
public static class SubstringFunction extends ScalarFunction {

  private boolean endInclusive;

  public SubstringFunction(boolean endInclusive) {
    this.endInclusive = endInclusive;
  }

  public String eval(String s, Integer begin, Integer end) {
    return s.substring(begin, endInclusive ? end + 1 : end);
  }
}

TableEnvironment env = TableEnvironment.create(...);

// 在 Table API 里不经注册直接“内联”调用函数
env.from("MyTable").select(call(new SubstringFunction(true), $("myField"), 5, 12));

// 注册函数
env.createTemporarySystemFunction("SubstringFunction", new SubstringFunction(true));
```
你可以在Table API中使用*表达式作为函数的一个参数，它将被扩展为该表所有的列作为函数对应位置的参数
```java
import org.apache.flink.table.api.*;
import org.apache.flink.table.functions.ScalarFunction;
import static org.apache.flink.table.api.Expressions.*;

public static class MyConcatFunction extends ScalarFunction {
  public String eval(@DataTypeHint(inputGroup = InputGroup.ANY) Object... fields) {
    return Arrays.stream(fields)
        .map(Object::toString)
        .collect(Collectors.joining(","));
  }
}

TableEnvironment env = TableEnvironment.create(...);

// 使用 $("*") 作为函数的参数，如果 MyTable 有 3 列 (a, b, c)，
// 它们都将会被传给 MyConcatFunction。
env.from("MyTable").select(call(MyConcatFunction.class, $("*")));

// 它等价于显式地将所有列传给 MyConcatFunction。
env.from("MyTable").select(call(MyConcatFunction.class, $("a"), $("b"), $("c")));
```
#### 开发指南
所有的自定义函数都遵循一些基本的实现原则
1. 函数类，实现类必须继承合适的基类，比如`org.apache.flink.table.functions.ScalarFunction`，必须是public的，不是abstract的，不允许使用非静态内部类或者匿名类，为了将自定义函数存储在持久化的 catalog 中，该类必须具有默认构造器，且在运行时可实例化。
2. 求值方法，基类提供了一组可以被重写的方法，比如open()、close()、isDeterministic()等，除了上述方法外，作用于每条传入记录的主要逻辑还必须通过专门的求值方法来实现，根据函数的种类，后台生成的运算符会在运行时调用诸如eval()、accumulate()或者retract()的求值方法，方法必须是public，带有一组定义明确的参数，方法支持的特性:
   - 可以实现重载方法，比如eval(Integer)与eval(LocalDateTime)
   - 使用变长参数，比如eval(Integer...)
   - 使用对象继承，比如eval(Object),可接受LocalDateTime与Integer作为参数;
   - 也可以组合使用，比如eval(Object...)可以接受所有类型的参数
```java
import org.apache.flink.table.functions.ScalarFunction;

// 有多个重载求值方法的函数
public static class SumFunction extends ScalarFunction {

  public Integer eval(Integer a, Integer b) {
    return a + b;
  }

  public Integer eval(String a, String b) {
    return Integer.valueOf(a) + Integer.valueOf(b);
  }

  public Integer eval(Double... d) {
    double result = 0;
    for (double value : d)
      result += value;
    return (int) result;
  }
}
```
3. 类型推导

Table是一种强类型的API，函数的参数与返回类型都必须映射到数据类型，从逻辑角度看，Planner需要知道数据类型、精度和小数位数，从JVM角度看，Planner在调用自定义函数时需要知道如何将内部数据结构表示为JVM对象，类型推导意在验证输入值、派生出参数/返回值数据类型的逻辑,Flink实现了自动的类型推导提取，通过反射及其求值方法中派生数据类型，如果这种隐式的反射提取方法不成功，可以通过使用@DataTypeHint和@FunctionHint注解相关参数、类或方法来支持提取过程，下面是个例子:
```java
import org.apache.flink.table.annotation.DataTypeHint;
import org.apache.flink.table.annotation.InputGroup;
import org.apache.flink.table.functions.ScalarFunction;
import org.apache.flink.types.Row;

// 有多个重载求值方法的函数
public static class OverloadedFunction extends ScalarFunction {

  // no hint required
  public Long eval(long a, long b) {
    return a + b;
  }

  // 定义 decimal 的精度和小数位
  public @DataTypeHint("DECIMAL(12, 3)") BigDecimal eval(double a, double b) {
    return BigDecimal.valueOf(a + b);
  }

  // 定义嵌套数据类型
  @DataTypeHint("ROW<s STRING, t TIMESTAMP_LTZ(3)>")
  public Row eval(int i) {
    return Row.of(String.valueOf(i), Instant.ofEpochSecond(i));
  }

  // 允许任意类型的符入，并输出序列化定制后的值
  @DataTypeHint(value = "RAW", bridgedTo = ByteBuffer.class)
  public ByteBuffer eval(@DataTypeHint(inputGroup = InputGroup.ANY) Object o) {
    return MyUtils.serializeToByteBuffer(o);
  }
}
```
如果需要更高级的类型推导逻辑，实现者可以在每个自定义函数中显示重写getTypeInference()方法，建议使用注解方式，它可以使自定义类型推导逻辑保持在受影响位置附近，而在其他位置则保持沉默状态.自动类型推导会检查函数的类和求值方法，派生出函数参数和结果的数据类型， @DataTypeHint 和 @FunctionHint 注解支持自动类型推导。有关可以隐式映射到数据类型的类的完整列表，请参阅[数据类型](https://nightlies.apache.org/flink/flink-docs-release-1.15/zh/docs/dev/table/types/#%e6%95%b0%e6%8d%ae%e7%b1%bb%e5%9e%8b%e6%b3%a8%e8%a7%a3)