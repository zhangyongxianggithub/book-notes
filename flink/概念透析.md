# Flink中的API
Flink为流/批应用程序的开发提供了不同级别的抽象:
![不同级别的抽象](pic/levels_of_abstraction.svg)
- Flink API最底层的抽象是有状态实时流处理，其抽象实现是[Process Function](https://nightlies.apache.org/flink/flink-docs-release-1.16/zh/docs/dev/datastream/operators/process_function/)，并且**Process Function**被Flink框架集成到了DataStream API中来为我们使用，它允许用户在应用程序中自由的处理来自单流或者多流的事件，并提供具有全局一致性和容错保障的状态。此外，用户可以在此层抽象中注册事件时间（event time）和处理时间(processing time)回调方法，从而允许程序可以实现复杂计算;
- Flink API的第二层抽象是Core APIs，许多应用程序不需要使用到上述最底层抽象的API，而是可以使用Core APIs进行编程，其中包含DataStream API(应用于有界/无界数据流场景)和DataSet API(应用于有界数据集场景)2部分。Core APIs提供的流式API为数据处理提供了通用的模块组件，例如各种形式的用户自定义转换(transformations)、联接(joins)、聚合(aggregations)、窗口(windows)和状态(state)操作等，此层API中处理的数据类型在没种编程语言中都有其对应的类。Process Function这类底层抽象和DataStream API的相互集成使得用户可以选择使用更底层的抽象API来实现自己的需求，DataSet API还额外提供了一些源语，比如循环/迭代操作;
- Flink API第三层抽象是Table API，Table API是以表为中心的声明式编程API，例如在流式数据场景下，它可以表示一张正在动态改变的表，Table API遵循关系模型: 即表拥有schema，并且Table API也提供了类似关系模型中的操作，比如select、project、join、group by和aggregate等，Table API程序是以声明的方式定义应执行的逻辑操作，而不是确切的指定程序应该执行的代码，尽管Table API使用起来很简洁并且可以由各种类型的用户自定义函数扩展功能，但还是比Core API的表达能力差，此外，Table API程序在执行之前还会使用优化器中的优化规则对用户编写的表达式进行优化，表和DataStream/DataSet可以进行无缝切换，Flink允许用户在编写应用程序时将Table API与DataStream/DataSet API混合使用;
- Flink API最顶层抽象是SQL，这层抽象在语义和程序表达上都类似于Table API，但是其程序实现都是SQL查询表达式，SQL抽象与Table API抽象之间的关联是非常紧密的，并且SQL查询语句可以在Table API中定义的表上执行。

# 有状态流处理
## 状态是什么
数据流中的很多操作一次只处理一个单一的事件，比如事件解析器，也有一些操作需要记录横跨多个事件的一些信息，比如窗口计算，这些计算就叫做有状态的。有状态计算的例子:
- 当一个应用搜索具体事件之间的关系模式，状态会存储连续的事件序列;
- 当按照分/小时/天单位维度聚合事件时，状态存储中间聚合状态;
- 当在数据流上训练机器学习模型时，状态需要保存模型参数;
- 当需要管理历史数据时，状态可以有效的访问历史事件。
Flink需要知道状态的存在以便通过checkpoints与savepoint机制实现容错，状态还支持Flink应用的扩缩容，也就是Flink会在并行的实例间重新分发状态。[可查询状态](https://nightlies.apache.org/flink/flink-docs-release-1.16/zh/docs/dev/datastream/fault-tolerance/queryable_state/)允许你从Flink外部访问状态。使用状态机制前，你需要了解[Flink's state backends](https://nightlies.apache.org/flink/flink-docs-release-1.16/zh/docs/ops/state/state_backends/)，Flink提供了多种state backends。
## Keyed State
分区状态可以被认为一种内嵌的key/value存储，有状态的操作读取流时，这些状态是在流上严格的分区并在在这些分区上分布的，因而，只允许在分区流上访问这些键值存储，比如，在一个keyed/partitioned数据交换操作后，访问键值存储只允许访问与当前的事件key相关联的value，对齐流的key与状态可以确保所有的状态更新都是本地操作，不需要事务的支持就可以保证数据一致性。这种对齐，也允许flink重新分发状态或者调整流的分区设置。
![分区状态](pic/state_partitioning.svg)
分区状态也会被深入组织成key groups，key groups是一种原子单元，Flink重新分发状态时，就是重新分发这种原子单元，key groups的数量与定义的最大并行度数量一样，在执行期间，每一个分区算子并行实例工作在一个或者多个key groups的keys上。
## State Persistence
Flink组合使用**流重放**机制与**checkpointing**机制实现了容错处理，一个checkpoint就是输入流中的一个特殊标记点，这个标记点还具有流经算子时对应的状态，流式数据流可以从一个checkpoint处重放，重放会保证数据一致性(精确一次处理语义)，这是通过存储的算子的状态并且从checkpoint标记点之后重放记录实现的。checkpoint间隔需要权衡考虑，综合焦虑执行期间的容错开销与恢复时的恢复时间(需要重放的记录数)。容错机制不断绘制分布式流式数据流的快照。对于状态较小的流式应用程序，这些快照非常轻量级，可以频繁绘制而不会对性能产生太大影响。 流应用程序的状态存储在可配置的位置，通常在分布式文件系统中。如果出现程序故障(由于机器、网络或软件故障)，Flink会停止分布式数据流。然后系统重新启动算子并将它们重置为最后成功的checkpoint。输入流被重置为状态快照标记点。重新启动的并行数据流处理的任何记录都保证不会影响先前的检查点状态。
默认情况下，checkpointing时关闭的，可以参考[Checkpointing]部分获得开启/配置checkpointing机制的细节。
为了使该机制实现其完全保证，数据流source(例如message queue或者broker)需要能够将流倒回到定义的最近点。[Apache Kafka](http://kafka.apache.org/)具有这种能力，Flink的Kafka connector利用了这一点。 有关Flink connectors提供的保证的更多信息，请参阅[数据源和数据汇的容错保证](https://nightlies.apache.org/flink/flink-docs-release-1.16/zh/docs/connectors/datastream/guarantees/)。因为Flink的checkpoints是通过分布式快照实现的，所以我们将snapshot和checkpoint互换使用。我们通常还使用术语snapshot来表示checkpoint或savepoint。
### Checkpointing
Flink容错机制的核心部分是对分布式数据流和算子状态绘制一致的快照。这些快照充当一致的checkpoints，系统可以在发生故障时回退到这些checkpoint。Flink绘制这些快照的机制在[Lightweight Asynchronous Snapshots for Distributed Dataflows](http://arxiv.org/abs/1506.08603)中有描述。它的灵感来自分布式快照的标准算法[Chandy-Lamport](http://research.microsoft.com/en-us/um/people/lamport/pubs/chandy.pdf)，Flink专门针对执行模型做了定制。请记住，与检查点有关的所有事情都可以异步完成。检查点barriers不会以锁的方式进行，并且操作可以异步快照其状态。从Flink 1.11版本开始，可以在对齐或不对齐的情况下记录checkpoints。在本节中，我们首先描述aligned checkpoints。
1. Barriers
   

