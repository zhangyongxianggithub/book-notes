# 第一章 引论
## 本书讨论的内容

# 第二章 算法分析
# 第10章 算法设计技巧
本章讨论用于求解问题的5种通常类型的算法，对于很对问题，这些方法中至少有一种是可以解决问题的。
## 贪婪算法
greedy algorithm，Dijkstra算法、Prim算法、Kruskal算法都是贪婪算法，贪婪算法分阶段的工作，每一个阶段都做最好的决定而不考虑整体，局部最优=全局最优，那么算法就是正确的，否则算法会得到一个次最优解，如果不要求绝对最佳答案，那么贪婪算法需要的计算可能比计算准确答案要简单很多。贪婪算法的例子比如钱币找零问题。
1. 一个简单的调度问题
有作业$j_1,j_2,...,j_N$，已知对应的运行时间分别是$t_1,t_2,...,t_N$，处理器只有一个，求作业平均完成时间的最小化，事实证明作业是按照最短作业最先进行，平均时间最小，证明如下,第一个作业以$t_1$时间完成，第二个作业以$t_1+t_2$时间完成，第三个作业以$t_1+t_2+t_3$时间完成，得到总的时间$C$如下:
$$ C=\sum ^{N}_{k=1} \left ( {N-k+1} \right ){t}_{k} $$
拆分公式得到
$$ C=\left ( {N+1} \right )\sum ^{N}_{k=1} {{t}_{k}}-\sum ^{N}_{k=1} {k}\cdot {t}_{k} $$
第一个和与作业的排序无关，只有第二个影响到总开销，第二个越大，则总开销越小，假如存在$x>y$使得$t_x<t_y$，
经过计算此时交换$t_x$与$t_y$第二个和增加，从而降低总开销，因此，所用时间不是单调非减的任何的作业调度都是次最优的，这个结果指出操作系统调度程序一般把优先权赋予那些更短作业的原因。
2. 哈夫曼编码
贪婪算法的第二个应用文件压缩，ASCII字符集包含100个左右的字符，所以需要至少需要$⌈log 100⌉=7$个bit，第8个bit作为奇偶校验位，如果字符集的大小是$C$那么标准的编码中就需要$⌈log C⌉$个bit，假设一个文件的字符信息如下:

|字符|编码|频率|bit数|
|:---|:---|:---|:---|
|a|000|10|30|
|e|001|15|45|
|i|010|12|36|
|s|011|3|9|
|t|100|4|12|
|空格|101|13|39|
|newline|110|1|3|
这个文件需要174个bit来表示，网络传输与磁盘存储需要更少的bit数，而不同的字符的出现频率是不同的，根绝这个特点，只要保证常出现的字符的bit短就能有效的减少总的传输量，
字符的二进制代码可以用二叉树表示0表示左分支，1表示右分支，如下图所示
![字符二叉树](adtjava/trie-%E7%AC%AC%201%20%E9%A1%B5.drawio.png)
现在就是要减少到每个叶节点的路径长度，比如nl字符它是仅有的儿子，可以放到上一层，减少一层
![字符二叉树](adtjava/trie-%E7%AC%AC%202%20%E9%A1%B5.drawio.png)
这是一颗满树，最优的编码总是满树，要不是叶节点，要不具有2个儿子，具有一个儿子的可以向上移动一层。

